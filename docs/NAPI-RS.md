# NAPI-RS documentation — vectorizer-napi

This document describes the **vectorizer-napi** addon: its architecture, use of NAPI-RS, the exposed API, and integration in a Node.js / TypeScript project.

**Reference:** [NAPI-RS — Getting started](https://napi.rs/docs/introduction/getting-started)

---

## 1. Overview

**vectorizer-napi** is a **native Node.js addon** (`.node` file) that exposes the vectorization logic of the Rust crate [vectorizer](../vectorizer):

- **Input:** a string (text).
- **Output:** an embedding vector (384 dimensions, **all-MiniLM-L6-v2** model).

It is built with [NAPI-RS](https://napi.rs) (napi + napi-derive) and runs in the same Node.js process, with no HTTP service or `child_process`.

### Compared to the HTTP service

| Aspect | vectorizer-napi (NAPI) | vectorizer (HTTP) |
|--------|------------------------|--------------------|
| Process | Same process as Node | Separate process / container |
| Latency | Direct call, no network | HTTP request (localhost or network) |
| Deployment | `.node` binary in `node_modules` | Docker image or standalone binary |
| Dependencies | Rust + libtorch at **build** time; at runtime only Node + `.node` | Same on the Rust server side |

---

## 2. NAPI-RS concepts used

### 2.1 Native addon (cdylib)

The crate is compiled as a **dynamic library** (`crate-type = ["cdylib"]`) to produce a `.node` file loaded by Node via `require()` / `import`. The entry point is declared in `build.rs` with `napi_build::setup()`.

- [NAPI-RS — Native module](https://napi.rs/docs/deep-dive/native-module)

### 2.2 Exports with `#[napi]`

Functions exposed to JavaScript are marked with the **`#[napi]`** macro:

- **`vectorize(text: string)`** — returns a **Promise** (see AsyncTask).
- **`model_name()`** — returns a **string** (synchronous).

TypeScript types (`index.d.ts`) and JavaScript glue (`index.js`) are generated by **`napi build`** from these signatures.

- [NAPI-RS — Exports](https://napi.rs/docs/concepts/exports)
- [NAPI-RS — Function](https://napi.rs/docs/concepts/function)

### 2.3 AsyncTask (async work)

Embedding computation (rust-bert) is **CPU-heavy**. To avoid blocking the Node.js main thread, it runs in the **libuv thread pool** via the **AsyncTask** pattern:

1. **`vectorize(text)`** creates an `AsyncTask<VectorizeTask>` and returns it immediately; Node treats it as a **Promise**.
2. **`compute()`** runs in a pool thread: load the model (once per thread), then `generate_embedding(model, text)`.
3. **`resolve()`** runs on the main thread: the `Vec<f32>` is converted to **Float64Array** and returned to JavaScript.

So the JS API is **async/await** without blocking the event loop.

- [NAPI-RS — AsyncTask](https://napi.rs/docs/concepts/async-task)

### 2.4 TypedArray (Float64Array)

The Rust output is `Vec<f32>`. To pass it to JavaScript without unnecessary copy, we use an **owned TypedArray**: here **Float64Array** (f32 → f64 on the Rust side to match the type documented in NAPI-RS). The array is shared between Rust and JS without extra serialization.

- [NAPI-RS — Typed Array](https://napi.rs/docs/concepts/typed-array)

### 2.5 Model loaded once per thread (thread-local)

The rust-bert model is heavy and is not **Sync** (it holds raw pointers). It is loaded **once per thread** in the libuv pool via **`thread_local!`** and **`RefCell<Option<SentenceEmbeddingsModel>>`**: each worker thread that runs `compute()` loads the model on first use and reuses it.

---

## 3. API reference

### 3.1 `vectorize(text: string): Promise<Float64Array>`

Vectorizes text and returns a **384-dimensional** vector (all-MiniLM-L6-v2 model).

| Parameter | Type | Description |
|-----------|------|-------------|
| `text` | `string` | Text to vectorize (job description, CV paragraph, etc.). |

**Returns:** `Promise<Float64Array>` — array of 384 Float64 numbers. On error (model load failure, embedding failure), the Promise is rejected with an error whose message describes the cause.

**Example:**

```javascript
const { vectorize } = require('./index.js');

const embedding = await vectorize('Full-stack Node.js developer, 3 years experience.');
console.log(embedding.length); // 384
console.log(Array.from(embedding.slice(0, 3)));
```

```typescript
import { vectorize } from './index.js';

const embedding: Float64Array = await vectorize('Your text here');
const asArray: number[] = Array.from(embedding);
```

---

### 3.2 `model_name(): string`

Returns the name of the model used for embeddings (for tracing or logging).

**Returns:** `"all-MiniLM-L6-v2"`.

**Example:**

```javascript
const { model_name } = require('./index.js');
console.log(model_name()); // "all-MiniLM-L6-v2"
```

---

## 4. Installation and build

### 4.1 Prerequisites

- **Node.js** ≥ 18
- **Rust** (rustup, stable toolchain)
- **libtorch** (for rust-bert / tch-rs): [tch-rs — Getting started](https://github.com/LaurentMazare/tch-rs#getting-started)  
  - Set the **`LIBTORCH`** environment variable to the extracted libtorch path, or use automatic download if available.

### 4.2 Build from source

```bash
cd vectorizer-napi
npm install
npm run build
```

- **`npm run build`**: `napi build --platform --release` — compiles for the current platform in release and generates `index.js`, `index.d.ts`, and `vectorizer.<platform>.node`.
- **`npm run build:debug`**: debug build (faster, for development).

### 4.3 Generated files

| File | Role |
|------|------|
| `index.js` | Loads the correct `.node` binary for OS/arch and re-exports the functions. |
| `index.d.ts` | TypeScript declarations (generated from `#[napi]`). |
| `vectorizer.<triple>.node` | Native binary (e.g. `vectorizer.darwin-arm64.node`). |

### 4.4 Targets

Targets are defined in **`package.json`** under **`napi.targets`**. Default:  
`x86_64-apple-darwin`, `aarch64-apple-darwin`, `x86_64-pc-windows-msvc`, `x86_64-unknown-linux-gnu`, `x86_64-unknown-linux-musl`, `aarch64-unknown-linux-gnu`, `aarch64-unknown-linux-musl`.

For a single target (e.g. current machine):

```bash
npx napi build --release
```

For multiple platforms (CI, npm publish):

```bash
npx napi build --platform --release
```

- [NAPI-RS — Build](https://napi.rs/docs/cli/build)
- [NAPI-RS — NAPI Config](https://napi.rs/docs/cli/napi-config)

---

## 5. Using in a Node.js / TypeScript project

### 5.1 Local use (vectorizor repo)

```javascript
// CommonJS
const { vectorize, model_name } = require('./vectorizer-napi/index.js');

async function main() {
  console.log('Model:', model_name());
  const emb = await vectorize('Hello world');
  console.log('Dimensions:', emb.length);
}
main().catch(console.error);
```

```typescript
// ESM
import { vectorize, model_name } from './vectorizer-napi/index.js';

const embedding: Float64Array = await vectorize('Your text');
const asNumbers: number[] = Array.from(embedding);
```

### 5.2 Integration in your app

If **vectorizer-napi** is copied or linked into your app (e.g. `npm link`, or subfolder of a monorepo):

```typescript
import { vectorize } from 'vectorizer-napi';

export async function vectorizeOffer(description: string): Promise<number[]> {
  const arr = await vectorize(description);
  return Array.from(arr);
}

export async function vectorizeCvExperience(paragraph: string): Promise<number[]> {
  return Array.from(await vectorize(paragraph));
}
```

No HTTP server or `child_process`; everything runs in the same process.

### 5.3 Using with a vector database (e.g. ruvector)

You can chain vectorizer-napi (embedding) with a vector DB (storage + search):

```typescript
import { VectorDB } from 'ruvector';
import { vectorize } from 'vectorizer-napi';

const db = VectorDB.withDimensions(384);

async function indexOffer(id: string, description: string) {
  const embedding = await vectorize(description);
  await db.insert({
    id,
    vector: new Float32Array(embedding),
    metadata: { description },
  });
}

async function searchSimilar(description: string, k = 10) {
  const queryEmbedding = await vectorize(description);
  return db.search({
    vector: new Float32Array(queryEmbedding),
    k,
  });
}
```

---

## 6. Troubleshooting

### Module load error (`.node` not found or dynamic error)

- Ensure **libtorch** is available at runtime (**`LIBTORCH`** or **`LD_LIBRARY_PATH`** depending on platform).
- Ensure the `.node` binary matches the OS and architecture (e.g. `darwin-arm64` on M1/M2).

### Error on first use of `vectorize` (model loading)

- The first call can be slow (downloading weights from Hugging Face).
- Check network access and, if needed, local model cache (per rust-bert configuration).

### Rust build fails (libtorch, linking)

- Follow the [tch-rs](https://github.com/LaurentMazare/tch-rs) docs to install libtorch and set **`LIBTORCH`**.
- On Linux, install the required system packages (cmake, clang, etc.).

### TypeScript: missing or wrong types

- After **`napi build`**, types are in **`index.d.ts`**. Ensure `package.json` has `"types": "index.d.ts"` and that your project resolves the `vectorizer-napi` module to this directory.

---

## 7. NAPI-RS references

| Topic | Link |
|-------|------|
| Getting started | https://napi.rs/docs/introduction/getting-started |
| A simple package | https://napi.rs/docs/introduction/simple-package |
| Exports | https://napi.rs/docs/concepts/exports |
| Function | https://napi.rs/docs/concepts/function |
| AsyncTask | https://napi.rs/docs/concepts/async-task |
| Typed Array | https://napi.rs/docs/concepts/typed-array |
| Build | https://napi.rs/docs/cli/build |
| NAPI Config | https://napi.rs/docs/cli/napi-config |

---

## 8. Summary

- **vectorizer-napi** exposes **`vectorize(text)`** (Promise) and **`model_name()`** (string) via NAPI-RS.
- Computation runs in the thread pool (AsyncTask); output is a 384D **Float64Array**.
- Build: **`npm run build`** in `vectorizer-napi`; prerequisites: Node ≥ 18, Rust, libtorch.
- For general package docs (installation, scripts, targets), see the vectorizer-napi [README](../README.md).
